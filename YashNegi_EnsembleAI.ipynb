{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGPYCBfniSmz",
        "outputId": "b3d94dcd-bab1-429d-f6cf-857a413d19e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NdLinear'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 50 (delta 18), reused 25 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (50/50), 66.50 KiB | 1.36 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "/content/NdLinear\n",
            "Processing /content/NdLinear\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate>=1.5.2 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (1.5.2)\n",
            "Requirement already satisfied: einops>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (2.0.2)\n",
            "Collecting pandas>=2.2.3 (from NdLinear==0.1.0)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (1.6.1)\n",
            "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.50.0 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (4.51.3)\n",
            "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from NdLinear==0.1.0) (0.21.0+cu124)\n",
            "Collecting matplotlib>=3.10.1 (from NdLinear==0.1.0)\n",
            "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "INFO: pip is looking at multiple versions of ndlinear to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Package 'ndlinear' requires a different Python: 3.11.12 not in '>=3.12'\u001b[0m\u001b[31m\n",
            "\u001b[0m/content\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ensemble-core/NdLinear.git\n",
        "%cd NdLinear\n",
        "!pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from NdLinear.ndlinear import NdLinear # Assuming NdLinear class is within ndlinear module inside the NdLinear directory"
      ],
      "metadata": {
        "id": "cogCa1dviWeF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLH94184iaXj",
        "outputId": "79e34438-7d4d-495b-8947-88028dc0718d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 42.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.15MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 11.0MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.89MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Normal(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_Normal, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.fc1 = nn.Linear(32 * 24 * 24, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3ULG6WIqiqzq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_NdLinear(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_NdLinear, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
        "        self.fc1 = NdLinear(input_dims=(32, 24, 24), hidden_size=(16, 12, 12))\n",
        "        self.fc2 = NdLinear(input_dims=(16, 12, 12), hidden_size=(10, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = x.view(x.size(0), -1) # flatten for final output\n",
        "        return x"
      ],
      "metadata": {
        "id": "URaJJ9Svixy4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion, trainloader, device):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(trainloader)\n",
        "\n",
        "def evaluate(model, testloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "W7rYlim-izoH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Normal Model\n",
        "model_normal = CNN_Normal().to(device)\n",
        "optimizer_normal = optim.Adam(model_normal.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# NdLinear Model\n",
        "model_ndlinear = CNN_NdLinear().to(device)\n",
        "optimizer_ndlinear = optim.Adam(model_ndlinear.parameters(), lr=0.001)\n",
        "\n",
        "# Train Both\n",
        "for epoch in range(10):\n",
        "    loss_normal = train(model_normal, optimizer_normal, criterion, trainloader, device)\n",
        "    loss_ndlinear = train(model_ndlinear, optimizer_ndlinear, criterion, trainloader, device)\n",
        "    print(f\"Epoch {epoch+1}, Normal Loss: {loss_normal:.4f}, NdLinear Loss: {loss_ndlinear:.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "acc_normal = evaluate(model_normal, testloader, device)\n",
        "acc_ndlinear = evaluate(model_ndlinear, testloader, device)\n",
        "\n",
        "print(f\"Normal Model Accuracy: {acc_normal*100:.2f}%\")\n",
        "print(f\"NdLinear Model Accuracy: {acc_ndlinear*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhbhfYTMi1iV",
        "outputId": "e9fb59ce-82ae-4094-e8ac-b035a9eab27f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Normal Loss: 0.1611, NdLinear Loss: 0.8033\n",
            "Epoch 2, Normal Loss: 0.0470, NdLinear Loss: 0.2516\n",
            "Epoch 3, Normal Loss: 0.0281, NdLinear Loss: 0.1780\n",
            "Epoch 4, Normal Loss: 0.0172, NdLinear Loss: 0.1450\n",
            "Epoch 5, Normal Loss: 0.0142, NdLinear Loss: 0.1270\n",
            "Epoch 6, Normal Loss: 0.0102, NdLinear Loss: 0.1141\n",
            "Epoch 7, Normal Loss: 0.0088, NdLinear Loss: 0.1017\n",
            "Epoch 8, Normal Loss: 0.0058, NdLinear Loss: 0.0931\n",
            "Epoch 9, Normal Loss: 0.0061, NdLinear Loss: 0.0841\n",
            "Epoch 10, Normal Loss: 0.0041, NdLinear Loss: 0.0769\n",
            "Normal Model Accuracy: 98.67%\n",
            "NdLinear Model Accuracy: 98.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_sn6G-2i3ZW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}